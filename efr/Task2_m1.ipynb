{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAcFCKQXP2gf",
        "outputId": "44911cb5-dd34-4d8b-f6d2-0ef2a1544ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BirQU64TP2T8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/NLP_assignment_4/'\n",
        "# file_path = '/kaggle/input/task2-data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Zz5ZUmSRKO",
        "outputId": "db31143b-0629-44ab-90ab-99d69241adad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.0+cpu)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.4.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xoe6_ANKbOcA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# model_name = 'DeepPavlov/bert-base-cased-conversational'\n",
        "model_name = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "emo_to_idx = {\"fear\": 0, \"disgust\": 1, \"anger\": 2, \"sadness\": 3, \"joy\": 4, \"surprise\": 5, \"neutral\": 6}\n",
        "idx_to_emo = {0: \"fear\", 1: \"disgust\", 2: \"anger\", 3: \"sadness\", 4: \"joy\", 5: \"surprise\", 6: \"neutral\"}\n",
        "\n",
        "def preprocess_data(data, tokenizer):\n",
        "    processed_data = []\n",
        "    for episode_data in data:\n",
        "        utterances = episode_data['utterances']\n",
        "        emotions = episode_data['emotions']\n",
        "        speakers = episode_data['speakers']\n",
        "        triggers = [0 if trg is None else trg for trg in episode_data['triggers']]\n",
        "\n",
        "        if not utterances or not emotions or not triggers or not speakers:\n",
        "            continue\n",
        "\n",
        "        tokens = tokenizer(utterances, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "        emotion_labels = [emo_to_idx[emotion] for emotion in emotions]\n",
        "\n",
        "        speaker_ids = tokenizer(speakers, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "        processed_data.append({\n",
        "            'input_ids': tokens['input_ids'],\n",
        "            'attention_mask': tokens['attention_mask'],\n",
        "            'emotion_labels': torch.tensor(emotion_labels, dtype=torch.long),  # Convert to tensor\n",
        "            'triggers': torch.tensor(triggers, dtype=torch.float),\n",
        "            'speaker_ids': speaker_ids['input_ids']\n",
        "        })\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# train_data_path = file_path +'train_file.json'\n",
        "# val_data_path = file_path + 'val_file.json'\n",
        "\n",
        "# with open(train_data_path, 'r') as file:\n",
        "#     train_data = json.load(file)\n",
        "\n",
        "# preprocessed_train_data = preprocess_data(train_data, tokenizer)\n",
        "\n",
        "# with open(val_data_path, 'r') as file:\n",
        "#     val_data = json.load(file)\n",
        "# preprocessed_val_data = preprocess_data(val_data, tokenizer)\n",
        "\n",
        "# print(preprocessed_train_data[0])\n",
        "\n",
        "# torch.save({\n",
        "#     'train': preprocessed_train_data,\n",
        "#     'val': preprocessed_val_data\n",
        "# }, file_path + 'preprocessed_data.pth')\n",
        "\n",
        "#demo\n",
        "test_data_path = '/content/drive/MyDrive/NLP_assignment_4/MELD_train_efr.json'\n",
        "\n",
        "with open(test_data_path, 'r') as file:\n",
        "    test_data = json.load(file)\n",
        "preprocessed_test_data = preprocess_data(test_data, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PZXRS2BavVcM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "loaded_data = torch.load(file_path + 'preprocessed_data.pth')\n",
        "\n",
        "loaded_train_data = loaded_data['train']\n",
        "loaded_val_data = loaded_data['val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q-kC90q0bOYG"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, preprocessed_data):\n",
        "        self.preprocessed_data = preprocessed_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.preprocessed_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.preprocessed_data[idx]\n",
        "        return {\n",
        "            'input_ids': item['input_ids'],\n",
        "            'attention_mask': item['attention_mask'],\n",
        "            'emotion_labels': item['emotion_labels'],\n",
        "            'triggers': item['triggers'],\n",
        "            'speaker_ids': item['speaker_ids']\n",
        "        }\n",
        "\n",
        "train_dataset = CustomDataset(loaded_train_data)\n",
        "val_dataset = CustomDataset(loaded_val_data)\n",
        "\n",
        "\n",
        "#demo\n",
        "test_dataset = CustomDataset(preprocessed_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOfjU8U1bOU_",
        "outputId": "4378c101-1591-4c3f-f7fb-81e632f7ea75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[[  101,  1192,   118,  1128,  7490,  1358,  1125,  2673,  1114, 23500,\n",
            "            136,   106,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101, 11205,   117,   170,  1376,  2113,   119,  1153,   118,  1131,\n",
            "            118,  1131,  2045,  1107,  1105,   146,  1354,  1131,  1108,  1128,\n",
            "           1105,   146,  4005,  1123,  1105,   102,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  1192,  1238,   112,   189,  4430,  1131,  1108,  3351,  1472,\n",
            "           3459,   136,   106,   102,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  2119,   146,  1108,  1198,  1177,  7215,  1106,  1267,  1128,\n",
            "            119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  2048,   119,   142,  2246,   106,   142,  2246,   106,   142,\n",
            "           2246,   106,   158,  5084,   106,   162,   112,  1221,  1184,   136,\n",
            "           1188,  1110,  1315,  6994,   119,   102,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0]],\n",
            "\n",
            "        [[  101,  4708,   117,  4268,  1274,   112,   189,  3368,  1240,  3307,\n",
            "           1149,  1303,   106,   102,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101, 18009,   117,  1105,  1191,  1128,   112,  1231,  6100,  1508,\n",
            "           1240,  1623,  1146,   117,  1725,  1274,   112,   189,  1128,  3465,\n",
            "           1113,  1103,   118,   102,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  8958,   117,  1817,  1140,  2041,   102,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  3100,  1128, 10275,  1146,   136,   102,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  2966,  1128,  1136,  2100,  1143,  1196,  1165,   146,  1500,\n",
            "           1128,  1115,  1155,  1104,  4945,  2042,   112,   188,  2053,  1132,\n",
            "          11314,   136,   106,   102,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  1262,  1115,  1152,   112,  1231,  1280,  1106,  1129,  5464,\n",
            "           2393,  3329,   106,   102,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  1302,   117,   146,  1225,   117,  1133,  1587,  1143,  1254,\n",
            "            117,  1272,  1122,   112,   188,  1177,  6376,   119,   102,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  2119,  1128,   112,  1231, 15005,  6709,   112,  1177,  3345,\n",
            "            106,  2825,   112,   189,  1128,  1202,  1122,  1251,  4946,   136,\n",
            "            102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  9300,   106,   102,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  3435,  1113,   106,   102,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,   146,  1274,   112,   189, 16445,  1294,  1251, 12572,   117,\n",
            "          15354,   136,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  1188,  1110,  1103,  1178, 20392,  1105,  1191,   146, 13084,\n",
            "           1122,  1146, 10565,   112,   188,  6100,  1129,  1176,  2048,   117,\n",
            "           2676,  1115, 17148,  1165,  4858, 15020,  1146,  1103,   189,  2047,\n",
            "          23445,   136,   102],\n",
            "         [  101,  1573,  1725,  1274,   112,   189,  1128,  1198,  1519,  1143,\n",
            "           3994,  1164,  1543,  1103,   189,  2047, 23445,  1105,  1128,  1198,\n",
            "           3994,  1164,  5497,  1122,   117, 15354,   136,   102,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  2048,   146,  1821,   106,   102,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0],\n",
            "         [  101,  5104,   117,  1191,  1128,  1274,   112,   189,  1587,  1172,\n",
            "            117,  1173,   146,  1209,   106,   102,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]), 'emotion_labels': tensor([[ 5,  0,  5,  3,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
            "        [ 1,  1,  2,  3,  5,  2,  6,  2,  2,  2,  2,  0,  6,  4,  2]]), 'triggers': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]), 'speaker_ids': tensor([[[  101, 19704,   102],\n",
            "         [  101,  3601,   102],\n",
            "         [  101, 19704,   102],\n",
            "         [  101,  3601,   102],\n",
            "         [  101, 19704,   102],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0],\n",
            "         [    0,     0,     0]],\n",
            "\n",
            "        [[  101,  8958,   102],\n",
            "         [  101,  8958,   102],\n",
            "         [  101, 19704,   102],\n",
            "         [  101,  9300,   102],\n",
            "         [  101,  9300,   102],\n",
            "         [  101,  9300,   102],\n",
            "         [  101,  4858,   102],\n",
            "         [  101,  9300,   102],\n",
            "         [  101,  4858,   102],\n",
            "         [  101,  4858,   102],\n",
            "         [  101,  4858,   102],\n",
            "         [  101,  4858,   102],\n",
            "         [  101,  4858,   102],\n",
            "         [  101,  9300,   102],\n",
            "         [  101,  8958,   102]]])}\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.functional import pad\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "\n",
        "    max_length = max(item['input_ids'].shape[1] for item in batch)\n",
        "    max_length_emotion_labels = max(item['emotion_labels'].shape[0] for item in batch)\n",
        "\n",
        "    input_ids_padded = pad_sequence([pad(item['input_ids'], (0, max_length - item['input_ids'].shape[1]), 'constant', 0) for item in batch], batch_first=True)\n",
        "    attention_mask_padded = pad_sequence([pad(item['attention_mask'], (0, max_length - item['attention_mask'].shape[1]), 'constant', 0) for item in batch], batch_first=True)\n",
        "    max_speaker_id_length = max(item['speaker_ids'].shape[1] for item in batch)\n",
        "\n",
        "    #Padding speaker_ids so they all have the same second dimension\n",
        "    speaker_ids_padded = pad_sequence([pad(item['speaker_ids'], (0, max_speaker_id_length - item['speaker_ids'].shape[1])) for item in batch], batch_first=True)\n",
        "\n",
        "    #Padding emotion_labels with a different padding value (-1)\n",
        "    emotion_labels_padded = pad_sequence([pad(item['emotion_labels'], (0, max_length_emotion_labels - item['emotion_labels'].shape[0]), 'constant', -1) for item in batch], batch_first=True)\n",
        "\n",
        "    triggers_padded = pad_sequence([item['triggers'] for item in batch], batch_first=True, padding_value=0)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids_padded,\n",
        "        'attention_mask': attention_mask_padded,\n",
        "        'emotion_labels': emotion_labels_padded,\n",
        "        'triggers': triggers_padded,\n",
        "        'speaker_ids': speaker_ids_padded\n",
        "    }\n",
        "\n",
        "sample_data = [train_dataset[i] for i in range(2)]\n",
        "collated_sample = custom_collate_fn(sample_data)\n",
        "t = 40\n",
        "num_labels = 7\n",
        "print(collated_sample)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=custom_collate_fn)\n",
        "\n",
        "\n",
        "# demo\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mDaIDktoqhh3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "device = 'cpu'\n",
        "\n",
        "class BertForEmotionClassificationWithSpeakerIDs(nn.Module):\n",
        "    def __init__(self, num_labels, speaker_id_embedding_size=20):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.speaker_embeddings = nn.Embedding(num_embeddings=102, embedding_dim=speaker_id_embedding_size)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size + speaker_id_embedding_size, 1)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, speaker_ids=None, labels=None):\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "        # print(\"Sequence output shape:\", sequence_output.shape)\n",
        "\n",
        "        speaker_embeddings = self.speaker_embeddings(speaker_ids)\n",
        "        speaker_embeddings = speaker_embeddings.unsqueeze(1).expand(-1, sequence_output.size(1), -1)\n",
        "\n",
        "        sequence_output = torch.cat((sequence_output, speaker_embeddings), dim=2)\n",
        "        # print(\"Concatenated output shape:\", sequence_output.shape)\n",
        "\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "        logits = logits.squeeze(-1)\n",
        "        # print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            logits = logits.view(-1, logits.shape[-1])\n",
        "            labels = labels.long()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_Hq1bf1Vn4y",
        "outputId": "d9007c88-2e2b-47d5-ce97-b0465c8877e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint loaded from /kaggle/input/models1/model_checkpoint_epoch_1.pth, starting training at epoch 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "checkpoint_files = [f for f in os.listdir(file_path) if f.startswith('model_checkpoint') and f.endswith('.pth')]\n",
        "if checkpoint_files:\n",
        "    latest_checkpoint_file = max(checkpoint_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "    checkpoint_path = os.path.join(file_path, latest_checkpoint_file)\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    model = BertForEmotionClassificationWithSpeakerIDs(num_labels).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    print(f\"Checkpoint loaded from {checkpoint_path}, starting training at epoch {start_epoch}\")\n",
        "else:\n",
        "    model = BertForEmotionClassificationWithSpeakerIDs(num_labels).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    num_epochs = 1\n",
        "    train_losses = []\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*num_epochs)\n",
        "    start_epoch = 0\n",
        "\n",
        "    print(\"No checkpoint found, starting training from scratch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "TA6isoDIy5y1",
        "outputId": "e1d4723f-9ebb-4dfd-ea09-24dce32ac89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average training loss: 6.265022221391237\n",
            "Epoch 2, Average training loss: 5.548839330673218\n",
            "Epoch 3, Average training loss: 5.315602254867554\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 3\n",
        "file_path_o = '/kaggle/working/'\n",
        "\n",
        "# model = BertForEmotionClassificationWithSpeakerIDs(num_labels).to(device)\n",
        "# optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*num_epochs)\n",
        "train_losses = []\n",
        "model.train()\n",
        "for epoch in range(start_epoch, num_epochs + 1):\n",
        "    total_loss = 0\n",
        "    i = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].view(-1, batch['input_ids'].size(-1))\n",
        "        attention_mask = batch['attention_mask'].view(-1, batch['attention_mask'].size(-1))\n",
        "        speaker_ids = batch['speaker_ids'][:, :, 0].view(-1)  # Shape: (batch_size * num_dialogues)\n",
        "        labels = batch['triggers'].view(-1)  # Shape: (batch_size * num_dialogues)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        speaker_ids = speaker_ids.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, speaker_ids=speaker_ids, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        i += 1\n",
        "        print(f\"Batch loss {i}: {loss.item()}\")\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_batch_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_batch_loss)\n",
        "\n",
        "    checkpoint_path = file_path_o + f'model_checkpoint_epoch_{epoch+1}.pth'\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': avg_batch_loss,\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f\"Epoch {i + 1}, Average training loss: {avg_batch_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L945GqPfbOOh",
        "outputId": "47eeacc2-1710-499a-c03e-0faa3b3bd5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape: torch.Size([480, 61])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 3.882808208465576\n",
            "\n",
            "Logits shape: torch.Size([768, 53])\n",
            "\n",
            "Labels shape: torch.Size([768])\n",
            "\n",
            "Current batch loss: 3.6156022548675537\n",
            "\n",
            "Logits shape: torch.Size([640, 38])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 3.140103816986084\n",
            "\n",
            "Logits shape: torch.Size([608, 40])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 3.0429956912994385\n",
            "\n",
            "Logits shape: torch.Size([768, 43])\n",
            "\n",
            "Labels shape: torch.Size([768])\n",
            "\n",
            "Current batch loss: 2.938504934310913\n",
            "\n",
            "Logits shape: torch.Size([576, 45])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 2.8124637603759766\n",
            "\n",
            "Logits shape: torch.Size([608, 95])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 3.273076295852661\n",
            "\n",
            "Logits shape: torch.Size([608, 48])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 2.563206434249878\n",
            "\n",
            "Logits shape: torch.Size([512, 43])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 2.2631194591522217\n",
            "\n",
            "Logits shape: torch.Size([608, 51])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 2.213648557662964\n",
            "\n",
            "Logits shape: torch.Size([576, 44])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 1.8896310329437256\n",
            "\n",
            "Logits shape: torch.Size([672, 39])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 1.6382980346679688\n",
            "\n",
            "Logits shape: torch.Size([576, 95])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 2.315858840942383\n",
            "\n",
            "Logits shape: torch.Size([608, 45])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 1.5309028625488281\n",
            "\n",
            "Logits shape: torch.Size([640, 40])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 1.4153666496276855\n",
            "\n",
            "Logits shape: torch.Size([672, 95])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 1.696561574935913\n",
            "\n",
            "Logits shape: torch.Size([672, 43])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 1.1381371021270752\n",
            "\n",
            "Logits shape: torch.Size([736, 48])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 1.0264321565628052\n",
            "\n",
            "Logits shape: torch.Size([640, 51])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 1.0098493099212646\n",
            "\n",
            "Logits shape: torch.Size([512, 41])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 1.0774587392807007\n",
            "\n",
            "Logits shape: torch.Size([736, 47])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.9116774797439575\n",
            "\n",
            "Logits shape: torch.Size([544, 49])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 1.055521011352539\n",
            "\n",
            "Logits shape: torch.Size([672, 43])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.7413020133972168\n",
            "\n",
            "Logits shape: torch.Size([544, 36])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.8211700916290283\n",
            "\n",
            "Logits shape: torch.Size([608, 53])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.7743302583694458\n",
            "\n",
            "Logits shape: torch.Size([608, 49])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.7610820531845093\n",
            "\n",
            "Logits shape: torch.Size([544, 43])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.8507590293884277\n",
            "\n",
            "Logits shape: torch.Size([736, 47])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.5903108716011047\n",
            "\n",
            "Logits shape: torch.Size([544, 50])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.7553219795227051\n",
            "\n",
            "Logits shape: torch.Size([672, 37])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.5509049892425537\n",
            "\n",
            "Logits shape: torch.Size([736, 48])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.5910570025444031\n",
            "\n",
            "Logits shape: torch.Size([576, 59])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.6717996001243591\n",
            "\n",
            "Logits shape: torch.Size([704, 37])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.4329099655151367\n",
            "\n",
            "Logits shape: torch.Size([544, 51])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.6569004058837891\n",
            "\n",
            "Logits shape: torch.Size([640, 38])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.512730598449707\n",
            "\n",
            "Logits shape: torch.Size([672, 50])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.4485020339488983\n",
            "\n",
            "Logits shape: torch.Size([672, 46])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.39535000920295715\n",
            "\n",
            "Logits shape: torch.Size([576, 42])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.42897921800613403\n",
            "\n",
            "Logits shape: torch.Size([768, 43])\n",
            "\n",
            "Labels shape: torch.Size([768])\n",
            "\n",
            "Current batch loss: 0.3213179111480713\n",
            "\n",
            "Logits shape: torch.Size([640, 53])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.3474832773208618\n",
            "\n",
            "Logits shape: torch.Size([672, 42])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.26863226294517517\n",
            "\n",
            "Logits shape: torch.Size([640, 51])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.3366779088973999\n",
            "\n",
            "Logits shape: torch.Size([672, 57])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.32120463252067566\n",
            "\n",
            "Logits shape: torch.Size([736, 42])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.28160393238067627\n",
            "\n",
            "Logits shape: torch.Size([608, 47])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.33566686511039734\n",
            "\n",
            "Logits shape: torch.Size([672, 37])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.3105238974094391\n",
            "\n",
            "Logits shape: torch.Size([672, 49])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.29996228218078613\n",
            "\n",
            "Logits shape: torch.Size([672, 48])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.2793407738208771\n",
            "\n",
            "Logits shape: torch.Size([640, 41])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.3003193438053131\n",
            "\n",
            "Logits shape: torch.Size([544, 39])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.3223796784877777\n",
            "\n",
            "Logits shape: torch.Size([576, 48])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.28757551312446594\n",
            "\n",
            "Logits shape: torch.Size([544, 47])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.28883010149002075\n",
            "\n",
            "Logits shape: torch.Size([640, 37])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.26964786648750305\n",
            "\n",
            "Logits shape: torch.Size([544, 51])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.42345866560935974\n",
            "\n",
            "Logits shape: torch.Size([672, 38])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.2710109353065491\n",
            "\n",
            "Logits shape: torch.Size([736, 47])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.34731465578079224\n",
            "\n",
            "Logits shape: torch.Size([544, 48])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.3531084656715393\n",
            "\n",
            "Logits shape: torch.Size([704, 40])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.27884572744369507\n",
            "\n",
            "Logits shape: torch.Size([704, 51])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.25135159492492676\n",
            "\n",
            "Logits shape: torch.Size([608, 41])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.30995091795921326\n",
            "\n",
            "Logits shape: torch.Size([608, 50])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.24462886154651642\n",
            "\n",
            "Logits shape: torch.Size([640, 44])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.2796465754508972\n",
            "\n",
            "Logits shape: torch.Size([608, 46])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.2584100663661957\n",
            "\n",
            "Logits shape: torch.Size([608, 48])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.2693425714969635\n",
            "\n",
            "Logits shape: torch.Size([480, 45])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.3480711579322815\n",
            "\n",
            "Logits shape: torch.Size([704, 50])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.245536670088768\n",
            "\n",
            "Logits shape: torch.Size([640, 95])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.27759993076324463\n",
            "\n",
            "Logits shape: torch.Size([512, 41])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 0.3242798447608948\n",
            "\n",
            "Logits shape: torch.Size([608, 51])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.2543100416660309\n",
            "\n",
            "Logits shape: torch.Size([576, 46])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.3337215483188629\n",
            "\n",
            "Logits shape: torch.Size([640, 44])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.22743770480155945\n",
            "\n",
            "Logits shape: torch.Size([768, 61])\n",
            "\n",
            "Labels shape: torch.Size([768])\n",
            "\n",
            "Current batch loss: 0.2164948731660843\n",
            "\n",
            "Logits shape: torch.Size([736, 51])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.22256778180599213\n",
            "\n",
            "Logits shape: torch.Size([672, 42])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.24866841733455658\n",
            "\n",
            "Logits shape: torch.Size([480, 57])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.3089408874511719\n",
            "\n",
            "Logits shape: torch.Size([544, 46])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.2962861657142639\n",
            "\n",
            "Logits shape: torch.Size([576, 35])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.23419594764709473\n",
            "\n",
            "Logits shape: torch.Size([640, 34])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.26159733533859253\n",
            "\n",
            "Logits shape: torch.Size([512, 53])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 0.36050063371658325\n",
            "\n",
            "Logits shape: torch.Size([576, 47])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.31243589520454407\n",
            "\n",
            "Logits shape: torch.Size([608, 43])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.1898239403963089\n",
            "\n",
            "Logits shape: torch.Size([672, 38])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.24604883790016174\n",
            "\n",
            "Logits shape: torch.Size([704, 47])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.22147439420223236\n",
            "\n",
            "Logits shape: torch.Size([576, 43])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2480897158384323\n",
            "\n",
            "Logits shape: torch.Size([736, 41])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.2073846459388733\n",
            "\n",
            "Logits shape: torch.Size([704, 57])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.22894519567489624\n",
            "\n",
            "Logits shape: torch.Size([672, 38])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.23942404985427856\n",
            "\n",
            "Logits shape: torch.Size([672, 48])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.21969115734100342\n",
            "\n",
            "Logits shape: torch.Size([608, 39])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.2336323857307434\n",
            "\n",
            "Logits shape: torch.Size([704, 49])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.21694068610668182\n",
            "\n",
            "Logits shape: torch.Size([640, 51])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.21042823791503906\n",
            "\n",
            "Logits shape: torch.Size([608, 59])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.26046764850616455\n",
            "\n",
            "Logits shape: torch.Size([672, 53])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.20481041073799133\n",
            "\n",
            "Logits shape: torch.Size([544, 44])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.22649988532066345\n",
            "\n",
            "Logits shape: torch.Size([544, 49])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.2502225637435913\n",
            "\n",
            "Logits shape: torch.Size([672, 59])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.23775993287563324\n",
            "\n",
            "Logits shape: torch.Size([704, 65])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.20318979024887085\n",
            "\n",
            "Logits shape: torch.Size([576, 48])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2966434955596924\n",
            "\n",
            "Logits shape: torch.Size([704, 40])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.20741239190101624\n",
            "\n",
            "Logits shape: torch.Size([672, 51])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.23163416981697083\n",
            "\n",
            "Logits shape: torch.Size([736, 43])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.18094591796398163\n",
            "\n",
            "Logits shape: torch.Size([672, 48])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.20028269290924072\n",
            "\n",
            "Logits shape: torch.Size([576, 95])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.27103161811828613\n",
            "\n",
            "Logits shape: torch.Size([480, 95])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.38031354546546936\n",
            "\n",
            "Logits shape: torch.Size([544, 48])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.26138296723365784\n",
            "\n",
            "Logits shape: torch.Size([704, 95])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.1844465136528015\n",
            "\n",
            "Logits shape: torch.Size([640, 47])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.22768564522266388\n",
            "\n",
            "Logits shape: torch.Size([576, 39])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.25630462169647217\n",
            "\n",
            "Logits shape: torch.Size([640, 61])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.26048988103866577\n",
            "\n",
            "Logits shape: torch.Size([608, 42])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.27254119515419006\n",
            "\n",
            "Logits shape: torch.Size([576, 43])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2218286395072937\n",
            "\n",
            "Logits shape: torch.Size([672, 41])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.22678548097610474\n",
            "\n",
            "Logits shape: torch.Size([704, 46])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.18981032073497772\n",
            "\n",
            "Logits shape: torch.Size([672, 50])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.25706955790519714\n",
            "\n",
            "Logits shape: torch.Size([640, 46])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.22696185111999512\n",
            "\n",
            "Logits shape: torch.Size([640, 41])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.17668482661247253\n",
            "\n",
            "Logits shape: torch.Size([576, 45])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.24225084483623505\n",
            "\n",
            "Logits shape: torch.Size([672, 43])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.17908602952957153\n",
            "\n",
            "Logits shape: torch.Size([672, 41])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.22453667223453522\n",
            "\n",
            "Logits shape: torch.Size([576, 95])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2544463872909546\n",
            "\n",
            "Logits shape: torch.Size([576, 51])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2679663896560669\n",
            "\n",
            "Logits shape: torch.Size([704, 61])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.20372766256332397\n",
            "\n",
            "Logits shape: torch.Size([704, 41])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.18038639426231384\n",
            "\n",
            "Logits shape: torch.Size([608, 43])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.20982466638088226\n",
            "\n",
            "Logits shape: torch.Size([576, 53])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.22008159756660461\n",
            "\n",
            "Logits shape: torch.Size([544, 37])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.28395047783851624\n",
            "\n",
            "Logits shape: torch.Size([704, 41])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.20202039182186127\n",
            "\n",
            "Logits shape: torch.Size([608, 39])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.1923280954360962\n",
            "\n",
            "Logits shape: torch.Size([544, 56])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.2643652856349945\n",
            "\n",
            "Logits shape: torch.Size([544, 48])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.25204434990882874\n",
            "\n",
            "Logits shape: torch.Size([640, 41])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.2950200140476227\n",
            "\n",
            "Logits shape: torch.Size([608, 48])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.23125667870044708\n",
            "\n",
            "Logits shape: torch.Size([576, 42])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.23972219228744507\n",
            "\n",
            "Logits shape: torch.Size([480, 37])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.2625870108604431\n",
            "\n",
            "Logits shape: torch.Size([640, 49])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.2123737335205078\n",
            "\n",
            "Logits shape: torch.Size([640, 45])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.22184643149375916\n",
            "\n",
            "Logits shape: torch.Size([704, 50])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.18570943176746368\n",
            "\n",
            "Logits shape: torch.Size([736, 56])\n",
            "\n",
            "Labels shape: torch.Size([736])\n",
            "\n",
            "Current batch loss: 0.21463440358638763\n",
            "\n",
            "Logits shape: torch.Size([672, 41])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.20193767547607422\n",
            "\n",
            "Logits shape: torch.Size([768, 41])\n",
            "\n",
            "Labels shape: torch.Size([768])\n",
            "\n",
            "Current batch loss: 0.13810080289840698\n",
            "\n",
            "Logits shape: torch.Size([672, 43])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.17949384450912476\n",
            "\n",
            "Logits shape: torch.Size([672, 42])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.2258169949054718\n",
            "\n",
            "Logits shape: torch.Size([640, 41])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.21504922211170197\n",
            "\n",
            "Logits shape: torch.Size([544, 39])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.2579227685928345\n",
            "\n",
            "Logits shape: torch.Size([640, 52])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.196801096200943\n",
            "\n",
            "Logits shape: torch.Size([512, 42])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 0.26797544956207275\n",
            "\n",
            "Logits shape: torch.Size([640, 40])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.19171759486198425\n",
            "\n",
            "Logits shape: torch.Size([608, 40])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.21693676710128784\n",
            "\n",
            "Logits shape: torch.Size([640, 39])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.21316976845264435\n",
            "\n",
            "Logits shape: torch.Size([608, 38])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.21169956028461456\n",
            "\n",
            "Logits shape: torch.Size([576, 61])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.26707756519317627\n",
            "\n",
            "Logits shape: torch.Size([608, 40])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.23481515049934387\n",
            "\n",
            "Logits shape: torch.Size([672, 56])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.2618831396102905\n",
            "\n",
            "Logits shape: torch.Size([672, 44])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.19406938552856445\n",
            "\n",
            "Logits shape: torch.Size([576, 48])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.24327248334884644\n",
            "\n",
            "Logits shape: torch.Size([608, 38])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.2328350991010666\n",
            "\n",
            "Logits shape: torch.Size([608, 42])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.19027985632419586\n",
            "\n",
            "Logits shape: torch.Size([672, 41])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.18272486329078674\n",
            "\n",
            "Logits shape: torch.Size([512, 49])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 0.2437281608581543\n",
            "\n",
            "Logits shape: torch.Size([608, 48])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.21243266761302948\n",
            "\n",
            "Logits shape: torch.Size([640, 49])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.18828900158405304\n",
            "\n",
            "Logits shape: torch.Size([576, 49])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2050105631351471\n",
            "\n",
            "Logits shape: torch.Size([672, 51])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.2489914447069168\n",
            "\n",
            "Logits shape: torch.Size([608, 43])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.21234405040740967\n",
            "\n",
            "Logits shape: torch.Size([608, 48])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.20605450868606567\n",
            "\n",
            "Logits shape: torch.Size([576, 51])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.21598851680755615\n",
            "\n",
            "Logits shape: torch.Size([640, 46])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.22871288657188416\n",
            "\n",
            "Logits shape: torch.Size([576, 52])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.2391970157623291\n",
            "\n",
            "Logits shape: torch.Size([608, 59])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.2725423276424408\n",
            "\n",
            "Logits shape: torch.Size([608, 49])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.23658308386802673\n",
            "\n",
            "Logits shape: torch.Size([672, 52])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.16632603108882904\n",
            "\n",
            "Logits shape: torch.Size([672, 95])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.2230553925037384\n",
            "\n",
            "Logits shape: torch.Size([704, 50])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.1716785579919815\n",
            "\n",
            "Logits shape: torch.Size([768, 44])\n",
            "\n",
            "Labels shape: torch.Size([768])\n",
            "\n",
            "Current batch loss: 0.16145633161067963\n",
            "\n",
            "Logits shape: torch.Size([608, 38])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.23778848350048065\n",
            "\n",
            "Logits shape: torch.Size([672, 40])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.22627657651901245\n",
            "\n",
            "Logits shape: torch.Size([608, 47])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.25895458459854126\n",
            "\n",
            "Logits shape: torch.Size([640, 42])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.2301759272813797\n",
            "\n",
            "Logits shape: torch.Size([480, 42])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.2733173370361328\n",
            "\n",
            "Logits shape: torch.Size([544, 44])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.272621214389801\n",
            "\n",
            "Logits shape: torch.Size([704, 38])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.20548588037490845\n",
            "\n",
            "Logits shape: torch.Size([640, 51])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.17734824120998383\n",
            "\n",
            "Logits shape: torch.Size([704, 51])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.1816171556711197\n",
            "\n",
            "Logits shape: torch.Size([704, 50])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.1708124279975891\n",
            "\n",
            "Logits shape: torch.Size([704, 49])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.2022482305765152\n",
            "\n",
            "Logits shape: torch.Size([672, 51])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.19218340516090393\n",
            "\n",
            "Logits shape: torch.Size([608, 57])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.22941669821739197\n",
            "\n",
            "Logits shape: torch.Size([544, 46])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.23871421813964844\n",
            "\n",
            "Logits shape: torch.Size([576, 43])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.22848889231681824\n",
            "\n",
            "Logits shape: torch.Size([704, 48])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.20284295082092285\n",
            "\n",
            "Logits shape: torch.Size([608, 50])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.21920621395111084\n",
            "\n",
            "Logits shape: torch.Size([672, 49])\n",
            "\n",
            "Labels shape: torch.Size([672])\n",
            "\n",
            "Current batch loss: 0.21602776646614075\n",
            "\n",
            "Logits shape: torch.Size([512, 52])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 0.222952738404274\n",
            "\n",
            "Logits shape: torch.Size([704, 59])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.22940374910831451\n",
            "\n",
            "Logits shape: torch.Size([704, 40])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.1795227974653244\n",
            "\n",
            "Logits shape: torch.Size([640, 41])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.22771160304546356\n",
            "\n",
            "Logits shape: torch.Size([512, 42])\n",
            "\n",
            "Labels shape: torch.Size([512])\n",
            "\n",
            "Current batch loss: 0.25724437832832336\n",
            "\n",
            "Logits shape: torch.Size([480, 56])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.207549586892128\n",
            "\n",
            "Logits shape: torch.Size([480, 43])\n",
            "\n",
            "Labels shape: torch.Size([480])\n",
            "\n",
            "Current batch loss: 0.2672952115535736\n",
            "\n",
            "Logits shape: torch.Size([608, 43])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.22443415224552155\n",
            "\n",
            "Logits shape: torch.Size([640, 40])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.21522457897663116\n",
            "\n",
            "Logits shape: torch.Size([640, 47])\n",
            "\n",
            "Labels shape: torch.Size([640])\n",
            "\n",
            "Current batch loss: 0.20040741562843323\n",
            "\n",
            "Logits shape: torch.Size([704, 49])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.18983778357505798\n",
            "\n",
            "Logits shape: torch.Size([544, 49])\n",
            "\n",
            "Labels shape: torch.Size([544])\n",
            "\n",
            "Current batch loss: 0.2653951048851013\n",
            "\n",
            "Logits shape: torch.Size([576, 39])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.24246232211589813\n",
            "\n",
            "Logits shape: torch.Size([576, 38])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.20646533370018005\n",
            "\n",
            "Logits shape: torch.Size([608, 45])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.21138028800487518\n",
            "\n",
            "Logits shape: torch.Size([576, 41])\n",
            "\n",
            "Labels shape: torch.Size([576])\n",
            "\n",
            "Current batch loss: 0.20997343957424164\n",
            "\n",
            "Logits shape: torch.Size([608, 47])\n",
            "\n",
            "Labels shape: torch.Size([608])\n",
            "\n",
            "Current batch loss: 0.22852259874343872\n",
            "\n",
            "Logits shape: torch.Size([704, 47])\n",
            "\n",
            "Labels shape: torch.Size([704])\n",
            "\n",
            "Current batch loss: 0.18579111993312836\n",
            "\n",
            "Logits shape: torch.Size([440, 51])\n",
            "\n",
            "Labels shape: torch.Size([440])\n",
            "\n",
            "Current batch loss: 0.18636509776115417\n",
            "\n",
            "Epoch 0, Average training loss: 0.0\n"
          ]
        }
      ],
      "source": [
        "# num_epochs = 1\n",
        "\n",
        "#\n",
        "# model = BertForEmotionClassificationWithSpeakerIDs(num_labels).to(device)\n",
        "# optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*num_epochs)\n",
        "\n",
        "# model.train()\n",
        "# train_losses = []\n",
        "# for epoch in range(num_epochs):\n",
        "#     total_loss = 0\n",
        "#     for batch in train_loader:\n",
        "#         input_ids = batch['input_ids'].view(-1, batch['input_ids'].size(-1))\n",
        "#         attention_mask = batch['attention_mask'].view(-1, batch['attention_mask'].size(-1))\n",
        "#         speaker_ids = batch['speaker_ids'][:, :, 0].view(-1)  # Shape: (batch_size * num_dialogues)\n",
        "#         labels = batch['triggers'].view(-1)  # Shape: (batch_size * num_dialogues)\n",
        "\n",
        "#         input_ids = input_ids.to(device)\n",
        "#         attention_mask = attention_mask.to(device)\n",
        "#         speaker_ids = speaker_ids.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask, speaker_ids=speaker_ids, labels=labels)\n",
        "#         loss = outputs.loss\n",
        "#         logits = outputs.logits\n",
        "\n",
        "#         # Backward pass\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     avg_batch_loss = total_loss / len(train_loader)\n",
        "#     train_losses.append(avg_batch_loss)\n",
        "\n",
        "#     checkpoint_path = file_path + f'model_checkpoint_epoch_{epoch+1}.pth'\n",
        "#     torch.save({\n",
        "#         'epoch': epoch,\n",
        "#         'model_state_dict': model.state_dict(),\n",
        "#         'optimizer_state_dict': optimizer.state_dict(),\n",
        "#         'loss': avg_batch_loss,\n",
        "#     }, checkpoint_path)\n",
        "\n",
        "#     print(f\"Checkpoint saved for epoch {epoch+1} at {checkpoint_path}\")\n",
        "#     print(f\"Epoch {epoch + 1}, Average training loss: {avg_batch_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_wg-xphGiUP",
        "outputId": "074505f6-baeb-4ba4-c902-8760759a3279"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "config.json: 100%|| 570/570 [00:00<00:00, 57.0kB/s]\n",
            "model.safetensors: 100%|| 436M/436M [00:25<00:00, 17.2MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to 'bert_emotion_classification_model_epoch_0.pt'\n"
          ]
        }
      ],
      "source": [
        "model_save_path = file_path + \"model_checkpoint_epoch_3.pt\"\n",
        "\n",
        "model = BertForEmotionClassificationWithSpeakerIDs(num_labels).to(device)\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model saved to '{model_save_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we3Y1cLSWC07",
        "outputId": "c14c4a2b-a310-41b1-886a-d32048be5f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 3.5175913439856634\n",
            "F1 Score: 0.4825366777094179\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pad_tensors_to_max_len(tensors, max_len):\n",
        "    padded_tensors = []\n",
        "    for tensor in tensors:\n",
        "        if tensor.dim() == 1:\n",
        "            if tensor.size(0) < max_len:\n",
        "                padded = F.pad(tensor, pad=(0, max_len - tensor.size(0)))\n",
        "            else:\n",
        "                padded = tensor\n",
        "        else:\n",
        "            if tensor.size(1) < max_len:\n",
        "                padded = F.pad(tensor, pad=(0, max_len - tensor.size(1)))\n",
        "            else:\n",
        "                padded = tensor\n",
        "        padded_tensors.append(padded)\n",
        "    return padded_tensors\n",
        "\n",
        "val_logits = []\n",
        "val_labels = []\n",
        "val_losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].view(-1, batch['input_ids'].size(-1))\n",
        "        attention_mask = batch['attention_mask'].view(-1, batch['attention_mask'].size(-1))\n",
        "        speaker_ids = batch['speaker_ids'][:, :, 0].view(-1)\n",
        "        labels = batch['triggers'].view(-1)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        speaker_ids = speaker_ids.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, speaker_ids=speaker_ids, labels=labels)\n",
        "        val_loss = outputs.loss\n",
        "        val_losses.append(val_loss.item())\n",
        "        logits = outputs.logits\n",
        "        val_logits.append(logits.detach().cpu())\n",
        "        val_labels.append(labels.detach().cpu())\n",
        "\n",
        "max_len = max(tensor.size(1) for tensor in val_logits)\n",
        "\n",
        "val_logits_padded = pad_tensors_to_max_len(val_logits, max_len)\n",
        "val_labels_padded = pad_tensors_to_max_len(val_labels, max_len)\n",
        "\n",
        "val_logit = torch.cat(val_logits_padded, dim=0)\n",
        "val_labels = torch.cat(val_labels_padded, dim=0)\n",
        "val_logits = torch.where(val_logit > t, torch.tensor(1.0), torch.tensor(0.0))\n",
        "\n",
        "val_preds = torch.argmax(val_logits, dim=-1)\n",
        "f1 = f1_score(val_labels.numpy(), val_preds.numpy(), average='macro')\n",
        "accuracy = accuracy_score(val_labels.numpy(), val_preds.numpy())\n",
        "\n",
        "print(f\"Validation Loss: {sum(val_losses) / len(val_losses)}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWp_QebK3-De",
        "outputId": "0c4ab7cb-4ce3-470f-e1a4-71dd8b25354b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_losses(train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fIUn9fG3-Df"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8f544a6edb5a43cea08c994b3c83e572",
            "51d3cc4d9c044ef4b1d431b1317842a0",
            "16391f972b58417ba9d5a429f28c9ea3",
            "7e034773e80140f7bb9872f5f8a4b66b",
            "f28b2aa57eb540ce874cc357410f65ec",
            "c6c35004a3444e1fb6dc044f6d31e419",
            "f654ab826b694da392e47c2f3b6310ea",
            "fc4c463740864c8abb19a99b73adb14f",
            "1b0faf8f5c5b41f8b4e2d2a5dc3eb658",
            "b38613943a234fa081df71a2c3771772",
            "f19fb4aec17f4a28aa46a6ac202f27cf"
          ]
        },
        "id": "XcZz0-AM3-Df",
        "outputId": "b5d96b1b-51d1-4f64-fdae-ad2b95798cbe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f544a6edb5a43cea08c994b3c83e572",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to '/content/drive/MyDrive/NLP_assignment_4//model_checkpoint_epoch_3.pt'\n"
          ]
        }
      ],
      "source": [
        "model_save_path = file_path + \"/model_checkpoint_epoch_3.pt\"\n",
        "\n",
        "model = BertForEmotionClassificationWithSpeakerIDs(num_labels).to(device)\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model saved to '{model_save_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqAMTGcE3-Df",
        "outputId": "b42e83d5-4d8b-4f53-d8c1-e3c371adcab1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pad_tensors_to_max_len(tensors, max_len):\n",
        "    padded_tensors = []\n",
        "    for tensor in tensors:\n",
        "        if tensor.dim() == 1:\n",
        "            if tensor.size(0) < max_len:\n",
        "                padded = F.pad(tensor, pad=(0, max_len - tensor.size(0)))\n",
        "            else:\n",
        "                padded = tensor\n",
        "        else:\n",
        "            if tensor.size(1) < max_len:\n",
        "                padded = F.pad(tensor, pad=(0, max_len - tensor.size(1)))\n",
        "            else:\n",
        "                padded = tensor\n",
        "        padded_tensors.append(padded)\n",
        "    return padded_tensors\n",
        "\n",
        "test_logits = []\n",
        "test_labels = []\n",
        "test_losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        try:\n",
        "            input_ids = batch['input_ids'].view(-1, batch['input_ids'].size(-1))\n",
        "            attention_mask = batch['attention_mask'].view(-1, batch['attention_mask'].size(-1))\n",
        "            speaker_ids = batch['speaker_ids'][:, :, 0].view(-1)\n",
        "            labels = batch['triggers'].view(-1)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            speaker_ids = speaker_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, speaker_ids=speaker_ids, labels=labels)\n",
        "            test_loss = outputs.loss\n",
        "            test_losses.append(test_loss.item())\n",
        "            logits = outputs.logits\n",
        "            test_logits.append(logits.detach().cpu())\n",
        "            test_labels.append(labels.detach().cpu())\n",
        "        except Exception as e:\n",
        "            print()\n",
        "\n",
        "max_len = max(tensor.size(1) for tensor in test_logits)\n",
        "\n",
        "test_logits_padded = pad_tensors_to_max_len(test_logits, max_len)\n",
        "test_labels_padded = pad_tensors_to_max_len(test_labels, max_len)\n",
        "\n",
        "test_logit = torch.cat(test_logits_padded, dim=0)\n",
        "test_labels = torch.cat(test_labels_padded, dim=0)\n",
        "test_logit_ = torch.where(torch.isnan(test_logit), torch.tensor(0.0), test_logit)\n",
        "test_logits = torch.where(test_logit_ > t, torch.tensor(1.0), torch.tensor(0.0))\n",
        "\n",
        "test_preds = torch.argmax(test_logits, dim=-1)\n",
        "f1 = f1_score(test_labels.numpy(), test_preds.numpy(), average='macro')\n",
        "accuracy = accuracy_score(test_labels.numpy(), test_preds.numpy())\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "datasetId": 4832152,
          "sourceId": 8166088,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4832990,
          "sourceId": 8167212,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4833449,
          "sourceId": 8167863,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30700,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16391f972b58417ba9d5a429f28c9ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4c463740864c8abb19a99b73adb14f",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b0faf8f5c5b41f8b4e2d2a5dc3eb658",
            "value": 435755784
          }
        },
        "1b0faf8f5c5b41f8b4e2d2a5dc3eb658": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d3cc4d9c044ef4b1d431b1317842a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6c35004a3444e1fb6dc044f6d31e419",
            "placeholder": "",
            "style": "IPY_MODEL_f654ab826b694da392e47c2f3b6310ea",
            "value": "model.safetensors:100%"
          }
        },
        "7e034773e80140f7bb9872f5f8a4b66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38613943a234fa081df71a2c3771772",
            "placeholder": "",
            "style": "IPY_MODEL_f19fb4aec17f4a28aa46a6ac202f27cf",
            "value": "436M/436M[00:02&lt;00:00,216MB/s]"
          }
        },
        "8f544a6edb5a43cea08c994b3c83e572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51d3cc4d9c044ef4b1d431b1317842a0",
              "IPY_MODEL_16391f972b58417ba9d5a429f28c9ea3",
              "IPY_MODEL_7e034773e80140f7bb9872f5f8a4b66b"
            ],
            "layout": "IPY_MODEL_f28b2aa57eb540ce874cc357410f65ec"
          }
        },
        "b38613943a234fa081df71a2c3771772": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c35004a3444e1fb6dc044f6d31e419": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f19fb4aec17f4a28aa46a6ac202f27cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28b2aa57eb540ce874cc357410f65ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f654ab826b694da392e47c2f3b6310ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4c463740864c8abb19a99b73adb14f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
